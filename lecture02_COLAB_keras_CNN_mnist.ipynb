{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lecture02_COLAB_keras_CNN_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "nmmviQymd9Sp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Keras MLP example for MNIST dataset\n",
        "[keras MNIST MLP example](https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py)"
      ]
    },
    {
      "metadata": {
        "id": "fWtRs-wCd147",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check Avalable GPU"
      ]
    },
    {
      "metadata": {
        "id": "XBH0kd4Gd5KK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "3c323460-22c9-4ab2-abbb-c4cd52261cd4"
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Sep  6 02:38:49 2018       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\r\n",
            "| N/A   39C    P8    30W / 149W |      0MiB / 11439MiB |      0%      Default |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                       GPU Memory |\r\n",
            "|  GPU       PID   Type   Process name                             Usage      |\r\n",
            "|=============================================================================|\r\n",
            "|  No running processes found                                                 |\r\n",
            "+-----------------------------------------------------------------------------+\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k64HjYQwdMDQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step1.\n",
        "configure tensorflow option"
      ]
    },
    {
      "metadata": {
        "id": "rx_J5LlvehNM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "this is critical option. TF memory control allow_growth is mandatory option\n",
        "'''\n",
        "import tensorflow as tf\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.Session(config=config )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Lr7VQDT-OOa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "check available GPU memory"
      ]
    },
    {
      "metadata": {
        "id": "lI8NXTrIe9yq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "193043a0-b80a-4890-a353-f82dedf9fc34"
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi   | grep MiB"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| N/A   39C    P0    71W / 149W |    115MiB / 11439MiB |      0%      Default |\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eTss08B_fQfM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "auwNPcrDfSpz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## import keras\n"
      ]
    },
    {
      "metadata": {
        "id": "rRCwOziBdbQZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "871cab06-744c-4fe5-8f62-8bd798d6c3ac"
      },
      "cell_type": "code",
      "source": [
        "'''Trains a simple deep NN on the MNIST dataset.\n",
        "\n",
        "Gets to 98.40% test accuracy after 20 epochs\n",
        "(there is *a lot* of margin for parameter tuning).\n",
        "2 seconds per epoch on a K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras import backend as K\n",
        "\n",
        "print('tensorflow ver. :',tf.__version__)\n",
        "print('keras      ver. :', keras.__version__)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow ver. : 1.10.1\n",
            "keras      ver. : 2.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nKuh13X9dfzj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## download mnist dataset and prepare train/test dataset"
      ]
    },
    {
      "metadata": {
        "id": "TAnLf2OPdeIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "b8ed85bf-aa5d-4fff-dc1a-b5567df8998a"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# the data, split between train and test sets\n",
        "#it will take time to download\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "CPU times: user 410 ms, sys: 106 ms, total: 515 ms\n",
            "Wall time: 1.89 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jxbrvl8Gdg0R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## reshape the dataset for keras category label"
      ]
    },
    {
      "metadata": {
        "id": "Cz6lCnx8fp0d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "6a791a23-31fa-4229-d5c6-d6b25dc48346"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "num_classes = 10\n",
        "\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "#for confusion matrix we need original label format\n",
        "y_test_cls=y_test\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "CPU times: user 93.1 ms, sys: 95.2 ms, total: 188 ms\n",
            "Wall time: 187 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QkzixpWNAn8h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check Dataset with Histogram"
      ]
    },
    {
      "metadata": {
        "id": "zAcWDEQr7GFy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "af457984-0422-401d-cbc8-97796ee3ecc5"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(y_test_cls, bins=20 )\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFKCAYAAADScRzUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6e7d861240>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "51s49M-tgbId",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## define model MLP(Multi Layer Perceptron)"
      ]
    },
    {
      "metadata": {
        "id": "zue_p27ydg-e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "8ee1b026-4d11-4f68-979a-66db6849aa7f"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iGCI8pkIdsKZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Configure Loss function and solver"
      ]
    },
    {
      "metadata": {
        "id": "8yqBI-XadsTJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#configure loss \n",
        "#configure solver(optimizer) sgd, adam\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A1CpGkWZdhIc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "9vhjXSMwdhQr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "311f71a7-1e7e-4023-85ce-5d7efa64c9b0"
      },
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.3, \n",
        "                    shuffle=True)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 18000 samples\n",
            "Epoch 1/10\n",
            "42000/42000 [==============================] - 10s 229us/step - loss: 0.2556 - acc: 0.9216 - val_loss: 0.0818 - val_acc: 0.9751\n",
            "Epoch 2/10\n",
            "42000/42000 [==============================] - 8s 188us/step - loss: 0.0831 - acc: 0.9750 - val_loss: 0.0562 - val_acc: 0.9833\n",
            "Epoch 3/10\n",
            "42000/42000 [==============================] - 8s 187us/step - loss: 0.0629 - acc: 0.9814 - val_loss: 0.0512 - val_acc: 0.9853\n",
            "Epoch 4/10\n",
            "42000/42000 [==============================] - 8s 187us/step - loss: 0.0510 - acc: 0.9840 - val_loss: 0.0447 - val_acc: 0.9872\n",
            "Epoch 5/10\n",
            "42000/42000 [==============================] - 8s 183us/step - loss: 0.0406 - acc: 0.9876 - val_loss: 0.0451 - val_acc: 0.9869\n",
            "Epoch 6/10\n",
            "42000/42000 [==============================] - 8s 181us/step - loss: 0.0342 - acc: 0.9898 - val_loss: 0.0500 - val_acc: 0.9868\n",
            "Epoch 7/10\n",
            "42000/42000 [==============================] - 8s 179us/step - loss: 0.0334 - acc: 0.9900 - val_loss: 0.0469 - val_acc: 0.9868\n",
            "Epoch 8/10\n",
            "42000/42000 [==============================] - 8s 179us/step - loss: 0.0316 - acc: 0.9909 - val_loss: 0.0474 - val_acc: 0.9873\n",
            "Epoch 9/10\n",
            "42000/42000 [==============================] - 8s 180us/step - loss: 0.0297 - acc: 0.9910 - val_loss: 0.0509 - val_acc: 0.9848\n",
            "Epoch 10/10\n",
            "42000/42000 [==============================] - 8s 181us/step - loss: 0.0294 - acc: 0.9912 - val_loss: 0.0455 - val_acc: 0.9882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "angeGGZCdhZd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## check test dataset"
      ]
    },
    {
      "metadata": {
        "id": "468MJcwmdhhl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "10beb957-1763-46c2-9767-c45580302375"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.035739749474732886\n",
            "Test accuracy: 0.9899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VcvKRmnbdhqc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "AxggKNe_6z93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1b1f0db-fb54-46ea-cfba-454767f5bacd"
      },
      "cell_type": "code",
      "source": [
        "y_test_cls"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "REKQRcbLdhxX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc10bcd1-81b3-4487-e6eb-8be456e3234b"
      },
      "cell_type": "code",
      "source": [
        "y_pred =model.predict_classes(x_test)\n",
        "y_pred\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "SNU2310Rlogy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1960
        },
        "outputId": "45078121-51f3-43a5-fbd9-b007bed16a80"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd_label = pd.DataFrame()\n",
        "pd_label[\"true\"]=y_test_cls\n",
        "pd_label[\"pred\"]=y_pred\n",
        "pd_label"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>true</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9970</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9971</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9972</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9973</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9974</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9975</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9976</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9977</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9978</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9979</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9980</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9981</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9982</th>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9983</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9984</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9985</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9986</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9987</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9988</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9989</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9990</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9991</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9992</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9993</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9994</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      true  pred\n",
              "0        7     7\n",
              "1        2     2\n",
              "2        1     1\n",
              "3        0     0\n",
              "4        4     4\n",
              "5        1     1\n",
              "6        4     4\n",
              "7        9     9\n",
              "8        5     5\n",
              "9        9     9\n",
              "10       0     0\n",
              "11       6     6\n",
              "12       9     9\n",
              "13       0     0\n",
              "14       1     1\n",
              "15       5     5\n",
              "16       9     9\n",
              "17       7     7\n",
              "18       3     3\n",
              "19       4     4\n",
              "20       9     9\n",
              "21       6     6\n",
              "22       6     6\n",
              "23       5     5\n",
              "24       4     4\n",
              "25       0     0\n",
              "26       7     7\n",
              "27       4     4\n",
              "28       0     0\n",
              "29       1     1\n",
              "...    ...   ...\n",
              "9970     5     5\n",
              "9971     2     2\n",
              "9972     4     4\n",
              "9973     9     9\n",
              "9974     4     4\n",
              "9975     3     3\n",
              "9976     6     6\n",
              "9977     4     4\n",
              "9978     1     1\n",
              "9979     7     7\n",
              "9980     2     2\n",
              "9981     6     6\n",
              "9982     5     6\n",
              "9983     0     0\n",
              "9984     1     1\n",
              "9985     2     2\n",
              "9986     3     3\n",
              "9987     4     4\n",
              "9988     5     5\n",
              "9989     6     6\n",
              "9990     7     7\n",
              "9991     8     8\n",
              "9992     9     9\n",
              "9993     0     0\n",
              "9994     1     1\n",
              "9995     2     2\n",
              "9996     3     3\n",
              "9997     4     4\n",
              "9998     5     5\n",
              "9999     6     6\n",
              "\n",
              "[10000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "-PU41smA86US",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "cf6a6d8d-39e0-4b08-ca68-a38c7d16e5d7"
      },
      "cell_type": "code",
      "source": [
        "  \n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_true=y_test_cls, y_pred=y_pred)    \n",
        "cm"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 977,    0,    1,    0,    0,    0,    1,    1,    0,    0],\n",
              "       [   0, 1130,    2,    1,    0,    0,    1,    1,    0,    0],\n",
              "       [   1,    1, 1022,    0,    0,    0,    0,    8,    0,    0],\n",
              "       [   0,    0,    1, 1004,    0,    2,    0,    2,    1,    0],\n",
              "       [   0,    0,    0,    0,  974,    0,    3,    0,    1,    4],\n",
              "       [   1,    0,    1,    6,    0,  880,    3,    1,    0,    0],\n",
              "       [   3,    2,    0,    0,    1,    1,  950,    0,    1,    0],\n",
              "       [   0,    2,    7,    0,    0,    0,    0, 1017,    1,    1],\n",
              "       [   3,    1,    3,    1,    0,    1,    0,    5,  958,    2],\n",
              "       [   2,    2,    1,    0,    3,    6,    0,    8,    0,  987]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "yg9rRtR__CWK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# rerun\n",
        "Keras train use last snapshot w/o any model modification"
      ]
    },
    {
      "metadata": {
        "id": "TK5CVD47_Bgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "56008b44-1e99-4997-85b7-aeba12ba58c8"
      },
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "batch_size = 128\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.3,\n",
        "                    shuffle=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 18000 samples\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 8s 189us/step - loss: 0.0290 - acc: 0.9910 - val_loss: 0.0562 - val_acc: 0.9879\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 8s 188us/step - loss: 0.0291 - acc: 0.9916 - val_loss: 0.0436 - val_acc: 0.9889\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 8s 190us/step - loss: 0.0290 - acc: 0.9916 - val_loss: 0.0508 - val_acc: 0.9892\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 8s 187us/step - loss: 0.0273 - acc: 0.9915 - val_loss: 0.0457 - val_acc: 0.9892\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 8s 189us/step - loss: 0.0293 - acc: 0.9913 - val_loss: 0.0537 - val_acc: 0.9882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hq9YNV34AMYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "74661a4f-bcfd-4dd3-ee2f-e20773070da5"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.046431761144646\n",
            "Test accuracy: 0.9892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "edgIG2mmACPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "949b2175-45bd-4972-eb9f-b86d0d43428f"
      },
      "cell_type": "code",
      "source": [
        "y_pred2 =model.predict_classes(x_test)\n",
        "cm = confusion_matrix(y_true=y_test_cls, y_pred=y_pred2)    \n",
        "cm"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 973,    1,    1,    1,    0,    0,    4,    0,    0,    0],\n",
              "       [   0, 1129,    1,    2,    0,    1,    1,    1,    0,    0],\n",
              "       [   0,    1, 1020,    0,    0,    0,    2,    8,    1,    0],\n",
              "       [   0,    0,    1,  997,    0,   11,    0,    0,    1,    0],\n",
              "       [   0,    0,    0,    0,  974,    0,    4,    0,    1,    3],\n",
              "       [   0,    0,    1,    1,    0,  887,    2,    1,    0,    0],\n",
              "       [   0,    2,    0,    0,    1,    3,  952,    0,    0,    0],\n",
              "       [   0,    3,    7,    0,    0,    0,    0, 1017,    1,    0],\n",
              "       [   2,    1,    1,    0,    0,    2,    2,    4,  960,    2],\n",
              "       [   2,    0,    1,    0,    5,   11,    0,    7,    0,  983]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}